Claro, aqu√≠ tienes el contenido del README.md reorganizado y estructurado en secciones claras, con t√≠tulos y formato mejorado para facilitar la lectura y comprensi√≥n:

---

# TFG: Plataforma de Autoevaluaci√≥n para Bases de Datos con IA üß†

**Trabajo Fin de Grado ‚Äî Miguel S√°nchez-Beato**

---

## Descripci√≥n

Esta aplicaci√≥n web ayuda a estudiantes de ‚ÄúSistemas de Bases de Datos‚Äù a autoevaluarse mediante un modelo de lenguaje grande (LLM, Llama 3). Los estudiantes pueden practicar, recibir feedback inmediato y hacer seguimiento de su progreso de forma intuitiva.

---

## √çndice

1. [Caracter√≠sticas principales](#caracter√≠sticas-principales)  
2. [Gu√≠a de instalaci√≥n y puesta en marcha](#gu√≠a-de-instalaci√≥n-y-puesta-en-marcha)  
    1. [Requisitos previos](#1-requisitos-previos)  
    2. [Clonar el repositorio](#2-clonar-el-repositorio)  
    3. [Configurar la base de datos](#3-configurar-la-base-de-datos)  
    4. [Instalar dependencias](#4-instalar-dependencias)  
    5. [Ejecutar el modelo LLM (Llama 3) con Docker](#5-ejecutar-el-modelo-llm-llama-3-con-docker)  
    6. [Iniciar el backend](#6-iniciar-el-backend)  
    7. [Iniciar el frontend](#7-iniciar-el-frontend)  
3. [Manual de usuario](#manual-de-usuario)

---

## Caracter√≠sticas principales

- **Dashboard de Progreso**  
  Visualiza tu avance general, el progreso por objetivos de aprendizaje y el total de preguntas respondidas, pendientes y falladas.

- **Evaluaci√≥n por Objetivos**  
  La aplicaci√≥n se estructura en torno a los objetivos de aprendizaje de la asignatura.

- **Generaci√≥n de Preguntas a Demanda**  
  Solicita nuevas preguntas para criterios de aceptaci√≥n espec√≠ficos y el modelo las generar√° para ti.

- **Feedback Instant√°neo**  
  Recibe al momento si tu respuesta es correcta (üü¢) o incorrecta (üî¥), junto con una explicaci√≥n detallada.

- **Historial de Intentos**  
  Guarda todos tus intentos, permitiendo reintentar preguntas falladas y seguir tu evoluci√≥n.

- **Notificaciones Intuitivas**  
  El sistema informa sobre el estado de las operaciones (√©xito, en proceso, error) mediante un c√≥digo de colores.

---

## Gu√≠a de instalaci√≥n y puesta en marcha

### 1. Requisitos previos

- **Docker Desktop** (v20.10 o superior)
- **Node.js** (v18.0 o superior)
- **npm** (incluido con Node.js)
- **M√≠nimo 8 GB de RAM**
- **Procesador Intel i7 de 7¬™ generaci√≥n o similar**
- **Conexi√≥n a Internet**

---

### 2. Clonar el repositorio

```bash
git clone https://github.com/Miguelsbdh/TFG.git
cd TFG
```

**Estructura del proyecto:**

```
cliente/
servidor/
README.md
tfg.sql
```

---

### 3. Configurar la base de datos üóÑÔ∏è

Se recomienda usar **XAMPP** para gestionar la base de datos MySQL.

1. Inicia los m√≥dulos de Apache y MySQL en XAMPP.
2. Accede a phpMyAdmin y ejecuta la siguiente consulta SQL para crear el usuario y darle permisos:

    ```sql
    -- Crea el usuario para conexiones locales y desde Docker
    CREATE USER 'tfg'@'localhost' IDENTIFIED BY 'tfg';
    CREATE USER 'tfg'@'%' IDENTIFIED BY 'tfg';
    GRANT ALL PRIVILEGES ON tfg.* TO 'tfg'@'localhost';
    GRANT ALL PRIVILEGES ON tfg.* TO 'tfg'@'%';
    FLUSH PRIVILEGES;
    ```

3. Crea la base de datos:

    ```sql
    CREATE DATABASE tfg;
    ```

4. Selecciona la base de datos `tfg` y usa la funci√≥n de importaci√≥n para cargar el archivo **tfg.sql** (en la ra√≠z del proyecto).

---

### 4. Instalar dependencias

Abre dos terminales en la ra√≠z del proyecto (una para el backend y otra para el frontend):

**Backend:**
```bash
cd servidor
npm install
```

**Frontend:**
```bash
cd cliente
npm install
```

---

### 5. Ejecutar el modelo LLM (Llama 3) con Docker üê≥

1. Descarga el modelo `llama-3-finetuned-bases-de-datos-unsloth.Q5_K_M.gguf` desde Hugging Face.
2. Guarda el archivo en una carpeta, por ejemplo: `C:/llama.cpp/models`.
3. Ejecuta el siguiente comando (ajusta la ruta en `-v` seg√∫n corresponda):

    ```bash
    docker run --rm -it -p 8000:8000 \
      -v /c/llama.cpp/models:/models \
      -e MODEL=/models/llama-3-finetuned-bases-de-datos-unsloth.Q5_K_M.gguf \
      ghcr.io/abetlen/llama-cpp-python:v0.3.1
    ```

**Nota:** Modifica la ruta `/c/llama.cpp/models` para que apunte a la carpeta donde guardaste el modelo `.gguf`.

---

### 6. Iniciar el backend

En la terminal del backend (`/servidor`):

```bash
npm start
```

El servidor quedar√° escuchando en el puerto **9001**.

---

### 7. Iniciar el frontend

En la terminal del frontend (`/cliente`):

```bash
npm run dev
```

La aplicaci√≥n se abrir√° autom√°ticamente en tu navegador en [http://localhost:9000](http://localhost:9000).

---

## Manual de usuario

1. **Inicio:**  
   Accede a [http://localhost:9000](http://localhost:9000). Ver√°s un dashboard con tu progreso.

2. **Selecciona un objetivo:**  
   Navega a una de las p√°ginas de objetivos de aprendizaje.

3. **Explora historias de usuario:**  
   Despliega una historia para ver sus criterios de aceptaci√≥n y el n√∫mero de preguntas disponibles.

4. **Genera preguntas (opcional):**  
   Si quieres m√°s preguntas, selecciona los criterios y pulsa "Solicitar m√°s preguntas".  
   *La generaci√≥n tarda unos 2.5 minutos por criterio. Una notificaci√≥n azul üîµ te informar√° del proceso.*

5. **Eval√∫ate:**  
   Pulsa "Evaluar historia" para comenzar un test.

6. **Responde y aprende:**  
   Selecciona tu respuesta y recibe feedback instant√°neo.

7. **Revisa tus resultados:**  
   Al final del test, ver√°s un resumen de tu desempe√±o.

---

¬øQuieres que el archivo est√© en espa√±ol formal, informal, o prefieres otro ajuste de tono? ¬øQuieres que adapte la estructura para documentaci√≥n en ingl√©s? ¬°D√≠melo si necesitas otra variante!
